from typing import List, Annotated
from typing_extensions import TypedDict
import operator
import httpx
import os
from langgraph.graph import StateGraph, END

class AgentState(TypedDict):
    initial_user_input: str # The initial information/topic from the user
    casey_question: str     # The question generated by Curious Casey
    finn_explanation: str   # The explanation provided by Factual Finn
    
    # We'll build up the conversation history as a list of tuples (speaker, message)
    # or just a list of strings for now.
    # Example: [("User", "info about X"), ("Casey", "question about X"), ("Finn", "explanation of X")]
    # For now, let's make it a list of strings to keep it simple.
    conversation_history: Annotated[List[str], operator.add] # operator.add will append to this list

BACKEND_API_BASE_URL = os.getenv("BACKEND_API_URL", "http://127.0.0.1:8000")

async def invoke_curious_casey(state: AgentState) -> dict:
    """
    Node function for Curious Casey.
    Takes the initial user input from the state, calls the /ask_follow_up API,
    and returns Casey's question to update the state.
    """
    print("---INVOKING CURIOUS CASEY NODE---")
    initial_input = state.get("initial_user_input")
    if not initial_input:
        print("Error: Initial user input not found in state for Curious Casey.")
        # In a real graph, you might want to handle this error more robustly
        # or transition to an error state. For now, we'll return an empty update.
        return {}

    print(f"Curious Casey received initial input: '{initial_input[:100]}...'")

    # Prepare the request for the /ask_follow_up endpoint
    payload = {"previous_statement": initial_input}
    api_url = f"{BACKEND_API_BASE_URL}/ask_follow_up"

    casey_question_text = ""
    new_history_entries = []

    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(api_url, json=payload, timeout=180.0) # Increased timeout
            response.raise_for_status() # Will raise an exception for 4XX/5XX errors

            response_data = response.json()
            casey_question_text = response_data.get("follow_up_question")

            if not casey_question_text:
                print("Error: 'follow_up_question' not found in API response or was empty.")
                casey_question_text = "Sorry, I couldn't think of a question right now." # Fallback
            else:
                print(f"Curious Casey generated question: '{casey_question_text}'")

        # Add to conversation history
        # We'll add the initial user input (framed as if it was a statement)
        # and then Casey's question.
        # Later, we might have a more structured history like (speaker, message)
        new_history_entries.append(f"Initial Topic: {initial_input}")
        new_history_entries.append(f"Curious Casey: {casey_question_text}")

    except httpx.HTTPStatusError as e:
        print(f"HTTP error calling /ask_follow_up for Curious Casey: {e.response.status_code} - {e.response.text}")
        casey_question_text = "Error: Could not get a question from Curious Casey due to an API error."
        new_history_entries.append(f"Error: API call to Curious Casey failed - {e.response.status_code}")
    except httpx.RequestError as e:
        print(f"Request error calling /ask_follow_up for Curious Casey: {e}")
        casey_question_text = "Error: Could not connect to the backend to get a question from Curious Casey."
        new_history_entries.append(f"Error: Network error calling Curious Casey - {e}")
    except Exception as e:
        print(f"An unexpected error occurred in invoke_curious_casey: {e}")
        import traceback
        traceback.print_exc()
        casey_question_text = "An unexpected error occurred while I was thinking of a question."
        new_history_entries.append(f"Error: Unexpected error in Curious Casey node - {e}")

    # Return the part of the state that this node is updating
    return {
        "casey_question": casey_question_text,
        "conversation_history": new_history_entries # LangGraph will append these
    }
    
async def invoke_factual_finn(state: AgentState) -> dict:
    """
    Node function for Factual Finn.
    Takes Casey's question and the initial user input from the state,
    calls the /explain API to get Finn's explanation,
    and returns Finn's explanation to update the state.
    """
    print("---INVOKING FACTUAL FINN NODE---")
    casey_question = state.get("casey_question")
    initial_input = state.get("initial_user_input")

    if not casey_question or not initial_input:
        print("Error: Casey's question or initial input not found in state for Factual Finn.")
        return {}

    print(f"Factual Finn received question: '{casey_question}' regarding: '{initial_input[:100]}...'")

    # Construct the instruction for Factual Finn to answer Casey's question
    # about the initial_input.
    # We want Finn to still explain the 'initial_input' but frame its explanation
    # in the context of Casey's question.
    # Option 1: Make Casey's question part of the 'input_text' for Finn's standard instruction.
    # This might be simpler for the existing /explain endpoint.

    # Let's try framing the instruction for Finn to explain the initial_input,
    # and its fine-tuning should make it address the most salient points,
    # hopefully aligning with what a good question from Casey would target.
    # A more advanced approach would be to modify the /explain endpoint or
    # create a new one that explicitly takes a "context" and a "question".
    # For now, let's have Finn explain the 'initial_input', and we assume
    # Casey's question has primed the context for what aspects are interesting.

    # The /explain endpoint expects "information_text" and an "instruction".
    # Factual Finn's default instruction is:
    # "Explain the following information in a direct and factual style, focusing on key points."
    # We will use the 'initial_user_input' as the 'information_text'.
    # Casey's question has set the stage. Finn will explain the initial_user_input.

    # An alternative and potentially better instruction for Finn here would be:
    # f"In response to the question: '{casey_question}', explain the relevant aspects of the following information in a direct and factual style, focusing on key points."
    # This makes Finn directly address Casey's question using the initial_input as context.
    # Let's use this more direct approach.

    finn_instruction = f"In response to the question: '{casey_question}', explain the relevant aspects of the following information in a direct and factual style, focusing on key points."

    payload = {
        "information_text": initial_input, # Finn explains the original topic
        "instruction": finn_instruction    # but guided by Casey's question
    }
    api_url = f"{BACKEND_API_BASE_URL}/explain"

    finn_explanation_text = ""
    new_history_entry = ""

    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(api_url, json=payload, timeout=180.0) # Increased timeout
            response.raise_for_status()

            response_data = response.json()
            finn_explanation_text = response_data.get("explanation")

            if not finn_explanation_text:
                print("Error: 'explanation' not found in API response from Factual Finn or was empty.")
                finn_explanation_text = "Sorry, I could not provide an explanation at this time." # Fallback
            else:
                print(f"Factual Finn generated explanation: '{finn_explanation_text[:200]}...'")

        new_history_entry = f"Factual Finn: {finn_explanation_text}"

    except httpx.HTTPStatusError as e:
        error_detail = e.response.text
        print(f"HTTP error calling /explain for Factual Finn: {e.response.status_code} - {error_detail}")
        finn_explanation_text = f"Error: Could not get an explanation from Factual Finn due to an API error ({e.response.status_code})."
        new_history_entry = f"Error: API call to Factual Finn failed - {e.response.status_code}"
    except httpx.RequestError as e:
        print(f"Request error calling /explain for Factual Finn: {e}")
        finn_explanation_text = "Error: Could not connect to the backend to get an explanation from Factual Finn."
        new_history_entry = f"Error: Network error calling Factual Finn - {e}"
    except Exception as e:
        print(f"An unexpected error occurred in invoke_factual_finn: {e}")
        import traceback
        traceback.print_exc()
        finn_explanation_text = "An unexpected error occurred while I was preparing an explanation."
        new_history_entry = f"Error: Unexpected error in Factual Finn node - {e}"

    return {
        "finn_explanation": finn_explanation_text,
        "conversation_history": [new_history_entry] # LangGraph will append this
    }
    
# --- Define the LangGraph Workflow ---
print("Defining LangGraph workflow...")
workflow = StateGraph(AgentState)

# Add the nodes to the graph
workflow.add_node("CURIOUS_CASEY", invoke_curious_casey)
workflow.add_node("FACTUAL_FINN", invoke_factual_finn)

# Define the edges for the conversational flow

# 1. Set the entry point: The graph will start with the CURIOUS_CASEY node.
workflow.set_entry_point("CURIOUS_CASEY")

# 2. From CURIOUS_CASEY, the conversation flows to FACTUAL_FINN.
workflow.add_edge("CURIOUS_CASEY", "FACTUAL_FINN")

# 3. For this initial simple graph, after FACTUAL_FINN speaks, the graph will end.
#    Later, we can make this conditional or loop back to CURIOUS_CASEY.
workflow.add_edge("FACTUAL_FINN", END) 

# Compile the graph into a runnable app
app_graph = workflow.compile()
print("LangGraph workflow compiled successfully.")